# EPISODE 26: MONITORING & OBSERVABILITY
**Season 7: Production & Advanced Topics** | Ğ ĞµĞ¹ĞºÑŒÑĞ²Ğ¸Ğº, Ğ˜ÑĞ»Ğ°Ğ½Ğ´Ğ¸Ñ ğŸ‡®ğŸ‡¸

> *"Without monitoring â€” you are blind. With bad monitoring â€” you are blind with false confidence. Good monitoring shows truth: what works, what breaks, what matters."* â€” GuÃ°rÃºn Ãsta

---

## ğŸ“‹ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ ĞĞ‘ Ğ­ĞŸĞ˜Ğ—ĞĞ”Ğ•

- **Ğ›Ğ¾ĞºĞ°Ñ†Ğ¸Ñ:** Ğ ĞµĞ¹ĞºÑŒÑĞ²Ğ¸Ğº, Verne Global Datacenter (monitoring center)
- **Ğ”Ğ½Ğ¸ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸:** 51-52 Ğ¸Ğ· 60
- **Ğ’Ñ€ĞµĞ¼Ñ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ:** 5-6 Ñ‡Ğ°ÑĞ¾Ğ²
- **Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ:** â­â­â­â­â˜†
- **Ğ¢Ğ¸Ğ¿:** Type B (Configuration â€” Prometheus + Grafana, minimal bash)

**ĞŸĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶Ğ¸:**
- **ĞœĞ°ĞºÑ Ğ¡Ğ¾ĞºĞ¾Ğ»Ğ¾Ğ²** â€” Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ³ĞµÑ€Ğ¾Ğ¹ (Ğ²Ñ‹), 49 Ğ´Ğ½ĞµĞ¹ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ·Ğ°Ğ´Ğ¸
- **Ğ’Ğ¸ĞºÑ‚Ğ¾Ñ€ ĞŸĞµÑ‚Ñ€Ğ¾Ğ²** â€” ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
- **GuÃ°rÃºn Ãsta** â€” Monitoring engineer, ex-DataDog, observability expert
- **BjÃ¶rn Sigurdsson** â€” Kubernetes SRE (ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ğ½Ñ‚)
- **LILITH v7.0** â€” AI-Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº (Production Mode)

**Ğ¦ĞµĞ»ÑŒ ÑĞ¿Ğ¸Ğ·Ğ¾Ğ´Ğ°:** ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ production monitoring Ğ´Ğ»Ñ Kubernetes infrastructure (Prometheus + Grafana + Alertmanager)

---

## ğŸ¬ PROLOGUE: Ğ‘Ğ•Ğ— Ğ“Ğ›ĞĞ— â€” Ğ¡Ğ›Ğ•ĞŸĞĞ™

### Ğ”ĞµĞ½ÑŒ 51, 09:00 â€” Verne Global Monitoring Center

ĞœĞ°ĞºÑ Ğ²Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ² monitoring center. Ğ¡Ñ‚ĞµĞ½Ğ° Ğ¸Ğ· Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¾Ğ²: Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ CPU, Memory, Network, Kubernetes pods. Real-time dashboards Ğ¼Ğ¸Ğ³Ğ°ÑÑ‚ Ğ·ĞµĞ»Ñ‘Ğ½Ñ‹Ğ¼ Ğ¸ Ğ¶Ñ‘Ğ»Ñ‚Ñ‹Ğ¼. Ğ’ Ñ†ĞµĞ½Ñ‚Ñ€Ğµ ĞºĞ¾Ğ¼Ğ½Ğ°Ñ‚Ñ‹ ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¶ĞµĞ½Ñ‰Ğ¸Ğ½Ğ° Ñ Ñ€Ñ‹Ğ¶Ğ¸Ğ¼Ğ¸ Ğ²Ğ¾Ğ»Ğ¾ÑĞ°Ğ¼Ğ¸, ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚ Ğ½Ğ° Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸.

**GuÃ°rÃºn:** "Welcome. I'm GuÃ°rÃºn Ãsta. Monitoring engineer. Ex-DataDog, now here. BjÃ¶rn told me about you â€” Kubernetes deployed, pods running, services exposed. Good. But question: how you know it works?"

**ĞœĞ°ĞºÑ:** "Ğ¯ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ â€” kubectl get pods, Ğ²ÑÑ‘ Running."

**GuÃ°rÃºn:** "Manual check. Every 5 minutes you run command? What if pod crashes at night? What if CPU 90% but still Running? What if memory leak grows slowly for 3 days?"

*[GuÃ°rÃºn ĞºĞ»Ğ¸ĞºĞ°ĞµÑ‚ Ğ¼Ñ‹ÑˆĞºĞ¾Ğ¹ â€” Ğ½Ğ° ÑĞºÑ€Ğ°Ğ½Ğµ Ğ¿Ğ¾ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Grafana dashboard Ñ 20 Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°Ğ¼Ğ¸]*

**GuÃ°rÃºn:** "This is production monitoring. Not 'kubectl get pods' every hour. Real-time metrics. Every second. CPU, memory, disk, network, HTTP requests, database queries, cache hit rate. Everything. And when something wrong â€” alert fires. SMS, email, Slack. Before users notice problem."

**ĞœĞ°ĞºÑ:** "Ğ’Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ»ÑÑÑ‰Ğµ. Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ ÑÑ‚Ğ¾ Ğ½Ğ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°Ñ‚ÑŒ?"

**GuÃ°rÃºn:** "For simple setup â€” 2 hours. For production-ready â€” 2 days. Today you learn basics: Prometheus collects metrics. Grafana visualizes. Alertmanager sends alerts. Tomorrow you have eyes."

**LILITH:** "ĞœĞ°ĞºÑ, Episode 25 Ğ´Ğ°Ğ» Ñ‚ĞµĞ±Ğµ Kubernetes. Episode 26 â€” Ğ³Ğ»Ğ°Ğ·Ğ° Ğ´Ğ»Ñ Kubernetes. Without monitoring â€” ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ½Ğ¾ Ñ‚Ñ‹ Ğ½Ğµ Ğ·Ğ½Ğ°ĞµÑˆÑŒ ĞºĞ°Ğº Ğ´Ğ¾Ğ»Ğ³Ğ¾. With monitoring â€” Ñ‚Ñ‹ Ğ²Ğ¸Ğ´Ğ¸ÑˆÑŒ Ğ²ÑÑ‘: health, performance, trends, anomalies. Production Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ visibility."

---

## ğŸ”„ Ğ¦Ğ˜ĞšĞ› 1: WHY MONITORING? (10 Ğ¼Ğ¸Ğ½ÑƒÑ‚)

### ğŸ¬ Ğ¡ÑĞ¶ĞµÑ‚ (2 Ğ¼Ğ¸Ğ½)

**GuÃ°rÃºn:** "Before we start â€” I tell story. DataDog, 2019. Customer runs e-commerce. Black Friday. 10x traffic. Everything looks good â€” 'kubectl get pods' shows all Running. Then â€” users report: checkout Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚. We investigate. Problem: memory leak in payment service. Pod Running, but service dead inside. Took 2 hours to find. Lost $500,000 revenue."

**GuÃ°rÃºn:** "If monitoring existed? Alert fires: 'Payment service response time > 5 seconds.' We investigate immediately. Fix in 10 minutes. Save $500,000. This is why monitoring matters."

**ĞœĞ°ĞºÑ:** "Ğ—Ğ½Ğ°Ñ‡Ğ¸Ñ‚ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ â€” ÑÑ‚Ğ¾ not just 'ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸', Ğ° 'Ğ·Ğ½Ğ°Ñ‚ÑŒ Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ñ… Ñ€Ğ°Ğ½ÑŒÑˆĞµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹'?"

**GuÃ°rÃºn:** "Exactly. Monitoring is early warning system. Problems always happen. Question is: who notices first â€” you or users? If you â€” fix before impact. If users â€” reputation damage, money loss, trust broken."

### ğŸ“š Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ: Observability Triangle (5-7 Ğ¼Ğ¸Ğ½)

**ĞœĞµÑ‚Ğ°Ñ„Ğ¾Ñ€Ğ°: Monitoring = Ğ”Ğ°Ñ‚Ñ‡Ğ¸ĞºĞ¸ Ğ² Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ¾Ğ±Ğ¸Ğ»Ğµ**

ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒ Ğ¼Ğ°ÑˆĞ¸Ğ½Ñƒ Ğ±ĞµĞ· dashboard:
- **Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ?** ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾ (ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸ÑˆÑŒ Ğ½Ğ° Ğ¿ĞµĞ¹Ğ·Ğ°Ğ¶ Ğ·Ğ° Ğ¾ĞºĞ½Ğ¾Ğ¼)
- **Ğ¢Ğ¾Ğ¿Ğ»Ğ¸Ğ²Ğ¾?** ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾ (Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ·Ğ°Ğ³Ğ»Ğ¾Ñ…Ğ»Ğ°)
- **Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»Ñ?** ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾ (Ğ¿Ğ¾ĞºĞ° Ğ´Ñ‹Ğ¼ Ğ½Ğµ Ğ¿Ğ¾ÑˆÑ‘Ğ»)

ĞœĞ°ÑˆĞ¸Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ½Ğ¾ Ñ‚Ñ‹ ÑĞ»ĞµĞ¿Ğ¾Ğ¹. ĞĞ´Ğ¸Ğ½ Ğ´Ğ°Ñ‚Ñ‡Ğ¸Ğº ÑĞ»Ğ¾Ğ¼Ğ°Ğ»ÑÑ â€” Ñ‚Ñ‹ Ğ½Ğµ ÑƒĞ·Ğ½Ğ°ĞµÑˆÑŒ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ¿Ğ¾Ğ·Ğ´Ğ½Ğ¾.

**Production ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° = Ñ‚Ğ° Ğ¶Ğµ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ°.** Ğ‘ĞµĞ· Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°:
- CPU 100%? Ğ£Ğ·Ğ½Ğ°ĞµÑˆÑŒ ĞºĞ¾Ğ³Ğ´Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ²Ğ¸ÑĞ½ĞµÑ‚
- Memory leak? Ğ£Ğ·Ğ½Ğ°ĞµÑˆÑŒ ĞºĞ¾Ğ³Ğ´Ğ° OOMKilled
- Disk 95% full? Ğ£Ğ·Ğ½Ğ°ĞµÑˆÑŒ ĞºĞ¾Ğ³Ğ´Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ fails

**Observability Triangle** (3 ÑÑ‚Ğ¾Ğ»Ğ¿Ğ° monitoring):

```
         ğŸ“Š METRICS
        (Prometheus)
       /            \
      /              \
     /                \
    /                  \
   /                    \
ğŸ“ LOGS          ğŸ” TRACES
(Loki/ELK)      (Jaeger)
```

**1. Metrics** (Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ):
- CPU usage: 45%
- Memory usage: 2.3 GB
- HTTP requests/sec: 1,240
- Response time: 150ms
- Error rate: 0.02%

**ĞšĞ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ:** Trends, alerting, dashboards (Episode 26 Ñ„Ğ¾ĞºÑƒÑ)

**2. Logs** (Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ):
- `2025-10-13 12:34:56 ERROR Database connection timeout`
- `2025-10-13 12:35:10 WARN Retry attempt 3/5`
- `2025-10-13 12:35:15 INFO Request processed successfully`

**ĞšĞ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ:** Debugging, audit trails (ÑƒĞ¶Ğµ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¾ Ğ² Season 1-3)

**3. Traces** (request flow):
- Request path: API â†’ Auth Service â†’ Database â†’ Cache â†’ Response
- Each step timing: 10ms â†’ 50ms â†’ 200ms â†’ 5ms â†’ 15ms
- Bottleneck: Database (200ms)

**ĞšĞ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ:** Performance debugging, microservices (advanced, beyond scope)

**Episode 26 Ñ„Ğ¾ĞºÑƒÑ: Metrics** (Prometheus + Grafana)

---

### **Prometheus: Time-series database Ğ´Ğ»Ñ metrics**

**Ğ§Ñ‚Ğ¾ ÑÑ‚Ğ¾:**
- Open-source monitoring system (CNCF project, ĞºĞ°Ğº Kubernetes)
- Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ metrics Ñ‡ĞµÑ€ĞµĞ· HTTP endpoints (scraping)
- Ğ¥Ñ€Ğ°Ğ½Ğ¸Ñ‚ ĞºĞ°Ğº time-series data (timestamp + value)
- ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ powerful query language (PromQL)

**ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PROMETHEUS SERVER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Retrievalâ”‚â”€â”€â†’â”‚Time-seriesâ”‚â”€â”€â†’â”‚  HTTP Server â”‚        â”‚
â”‚  â”‚ (scrape) â”‚   â”‚  Database â”‚   â”‚   (API)      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       â†“                                  â†‘               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚ Alertmanager â”‚ (alerts)                    â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                           â†‘
    (scrape metrics)            (query metrics)
         â†“                           â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TARGETS        â”‚          â”‚   GRAFANA    â”‚
â”‚  - Kubernetes   â”‚          â”‚  (dashboards)â”‚
â”‚  - Node Exporterâ”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  - Apps         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ĞšĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚:**

1. **Targets expose metrics:**
```
# Kubernetes pod exposes /metrics endpoint
http://my-app:8080/metrics

# Output (Prometheus format):
http_requests_total{method="GET",status="200"} 1523
http_requests_total{method="POST",status="201"} 342
memory_usage_bytes 2147483648
cpu_usage_seconds_total 456.78
```

2. **Prometheus scrapes targets** (pulls metrics every 15-30 seconds):
```yaml
scrape_configs:
  - job_name: 'kubernetes-pods'
    scrape_interval: 15s
    kubernetes_sd_configs:
      - role: pod
```

3. **Data stored as time-series:**
```
Metric: http_requests_total{method="GET"}
Timestamp 1: 1000 requests
Timestamp 2: 1050 requests (+50 in 15 sec)
Timestamp 3: 1120 requests (+70 in 15 sec)
...
```

4. **Query with PromQL:**
```promql
rate(http_requests_total[5m])  # Requests per second (5-min window)
```

5. **Alerting rules:**
```yaml
- alert: HighCPU
  expr: cpu_usage > 0.9
  for: 5m
  annotations:
    summary: "CPU usage > 90% for 5 minutes"
```

---

### **Grafana: Visualization Ğ´Ğ»Ñ Prometheus**

**Ğ§Ñ‚Ğ¾ ÑÑ‚Ğ¾:**
- Open-source dashboards and visualization
- Connects to Prometheus (and other data sources)
- Beautiful graphs, charts, tables
- Templating, variables, annotations

**ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ñ‚ Prometheus?**
- Prometheus = data collection & storage (backend)
- Grafana = visualization & exploration (frontend)
- Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ concerns: Prometheus Ñ„Ğ¾ĞºÑƒÑ Ğ½Ğ° reliability, Grafana Ğ½Ğ° UX

---

### **Alertmanager: Notifications Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼**

**Ğ§Ñ‚Ğ¾ ÑÑ‚Ğ¾:**
- Handles alerts Ğ¾Ñ‚ Prometheus
- Deduplication (same alert Ğ½Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ 100 Ñ€Ğ°Ğ·)
- Grouping (multiple related alerts â†’ one notification)
- Routing (Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ alerts â†’ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ ĞºĞ°Ğ½Ğ°Ğ»Ñ‹)
- Silencing (Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ alerts)

**Alert flow:**
```
Prometheus detects: CPU > 90%
      â†“
Prometheus fires alert â†’ Alertmanager
      â†“
Alertmanager processes:
  - Deduplicates (same alert already sent?)
  - Groups (CPU alert + Memory alert = "Server Issues")
  - Routes to channel (Slack/Email/PagerDuty)
      â†“
Notification sent â†’ Team responds
```

---

**Best Practices:**

âœ… **DO:**
- Monitor Ñ‡Ñ‚Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾ (not everything)
- Set alerts Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ (not cosmetic issues)
- Use dashboards Ğ´Ğ»Ñ exploration, alerts Ğ´Ğ»Ñ action
- Define SLOs (Service Level Objectives) â€” target metrics

âŒ **DON'T:**
- Alert Ğ½Ğ° Ğ²ÑÑ‘ (alert fatigue â†’ ignored alerts)
- Monitor metrics you don't understand
- Set alerts Ğ±ĞµĞ· runbooks (Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ³Ğ´Ğ° alert fires?)
- Ğ—Ğ°Ğ±Ñ‹Ğ²Ğ°Ğ¹ Ğ¿Ñ€Ğ¾ retention (metrics Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑÑ 15 Ğ´Ğ½ĞµĞ¹ default, Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ´Ğ»Ñ production)

**GuÃ°rÃºn's wisdom:**
> "Good monitoring answers 3 questions: What is broken? Why is broken? What to do? Bad monitoring shows 1000 metrics but no answers. Focus on actionable insights, not vanity metrics."

**LILITH:**
> "Monitoring â€” ÑÑ‚Ğ¾ Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ 'ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¸ Ñ€Ğ°Ğ´Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ·ĞµĞ»Ñ‘Ğ½Ñ‹Ğ¼ Ğ»Ğ¸Ğ½Ğ¸ÑĞ¼'. Ğ­Ñ‚Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ñ€Ğ°Ğ½Ğ½ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ. CPU 80% â€” ĞµÑ‰Ñ‘ Ğ½Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°. CPU 80% Ğ¸ Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚ â€” Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ñ‡ĞµÑ€ĞµĞ· 10 Ğ¼Ğ¸Ğ½ÑƒÑ‚. Monitoring Ğ²Ğ¸Ğ´Ğ¸Ñ‚ Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹, Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ snapshots. Kubectl Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ 'ÑĞµĞ¹Ñ‡Ğ°Ñ'. Prometheus Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ 'Ñ‡Ñ‚Ğ¾ Ğ±Ñ‹Ğ»Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚'."

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° (3-5 Ğ¼Ğ¸Ğ½)

**Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 1: ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ°**

Scenario: Production web app, 1000 req/sec.

ĞšĞ°ĞºĞ¸Ğµ metrics Ğ²Ğ°Ğ¶Ğ½Ñ‹ Ğ´Ğ»Ñ monitoring? (Ğ²Ñ‹Ğ±ĞµÑ€Ğ¸ 5 ÑĞ°Ğ¼Ñ‹Ñ… ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ…)

<details>
<summary>ğŸ’¡ Ğ”ÑƒĞ¼Ğ°Ğ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹</summary>

**Top 5 ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:**

1. **Request rate** (requests/sec)
   - ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ: Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ traffic spikes Ğ¸Ğ»Ğ¸ drops
   - Alert: Ğ•ÑĞ»Ğ¸ ÑƒĞ¿Ğ°Ğ» Ğ½Ğ° 50% â†’ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°

2. **Error rate** (%  HTTP 5xx errors)
   - ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ: ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ broken functionality
   - Alert: Ğ•ÑĞ»Ğ¸ > 1% â†’ users affected

3. **Response time** (p95 latency)
   - ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ: User experience metric
   - Alert: Ğ•ÑĞ»Ğ¸ > 500ms â†’ slow Ğ´Ğ»Ñ users

4. **CPU usage** (%)
   - ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ: Resource saturation indicator
   - Alert: Ğ•ÑĞ»Ğ¸ > 90% â†’ risk of crash

5. **Memory usage** (%)
   - ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ: Memory leaks detection
   - Alert: Ğ•ÑĞ»Ğ¸ Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚ continuously â†’ OOMKilled soon

**Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹ (Ğ½Ğ¾ Ğ½Ğµ top 5):**
- Disk I/O, Network bandwidth, Database connections, Cache hit rate

**Vanity metrics (Ğ½Ğµ critical):**
- Total users count (Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾, Ğ½Ğ¾ Ğ½Ğµ Ğ´Ğ»Ñ alerts)
- Number of features (Ğ½Ğµ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° availability)

</details>

### ğŸ¤” Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ LILITH (1 Ğ¼Ğ¸Ğ½)

**LILITH:** "Kubernetes pod status: Running. CPU: 95%. Memory: 90%. Response time: 10 seconds (Ğ±Ñ‹Ğ»Ğ¾ 100ms). Kubectl Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ 'Running'. ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° ĞµÑÑ‚ÑŒ?"

<details>
<summary>ğŸ’¡ Ğ”ÑƒĞ¼Ğ°Ğ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹</summary>

**ĞÑ‚Ğ²ĞµÑ‚:** **Ğ”Ğ, ÑĞµÑ€ÑŒÑ‘Ğ·Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°!**

**ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ:**
- Pod status = Running (ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ¶Ğ¸Ğ²)
- ĞĞ¾ service degraded (response time 100x slower)
- CPU/Memory near saturation â†’ bottleneck
- Users experiencing slowness (10 sec intolerable)

**kubectl limitations:**
- ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ container status (alive/dead)
- ĞĞ• Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ service health (fast/slow)
- ĞĞ• Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ resource saturation
- ĞĞ• Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ trends (ÑƒÑ…ÑƒĞ´ÑˆĞ°ĞµÑ‚ÑÑ Ğ»Ğ¸?)

**Monitoring Ğ²Ğ¸Ğ´Ğ¸Ñ‚:**
- Response time Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº: Ğ±Ñ‹Ğ» 100ms, ÑÑ‚Ğ°Ğ» 10s (Ñ€ĞµĞ·ĞºĞ¸Ğ¹ ÑĞºĞ°Ñ‡Ğ¾Ğº)
- CPU usage: Ğ¿Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ½Ğ¾ 95% (saturation)
- Alert fires: "Response time > 1s for 5 minutes"

**Ğ’Ñ‹Ğ²Ğ¾Ğ´:** kubectl Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ "Ğ²ÑÑ‘ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚". Monitoring Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ "Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ½Ğ¾ Ğ¿Ğ»Ğ¾Ñ…Ğ¾". Ğ”Ğ»Ñ production Ğ½ÑƒĞ¶ĞµĞ½ monitoring, Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ kubectl.

</details>

---

## ğŸ”„ Ğ¦Ğ˜ĞšĞ› 2: PROMETHEUS ARCHITECTURE (12 Ğ¼Ğ¸Ğ½ÑƒÑ‚)

### ğŸ¬ Ğ¡ÑĞ¶ĞµÑ‚ (2 Ğ¼Ğ¸Ğ½)

**Ğ”ĞµĞ½ÑŒ 51, 10:30 â€” Prometheus installation Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ**

**GuÃ°rÃºn:** "First â€” understand how Prometheus works. Not magic. Simple design: pull metrics from targets, store in database, allow queries. Let me show architecture."

*[GuÃ°rÃºn Ñ€Ğ¸ÑÑƒĞµÑ‚ Ğ½Ğ° whiteboard Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Prometheus]*

**GuÃ°rÃºn:** "Prometheus = time-series database. Every metric â€” series of (timestamp, value) pairs. Example: CPU usage at 10:00 = 45%, at 10:01 = 47%, at 10:02 = 50%. Time-series. Prometheus stores millions of these."

**ĞœĞ°ĞºÑ:** "Ğ Ğ¾Ñ‚ĞºÑƒĞ´Ğ° Prometheus Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ metrics? ĞšĞ°Ğ¶Ğ´Ğ¾Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ?"

**GuÃ°rÃºn:** "No. Prometheus **pulls** metrics (scraping model). Your application exposes /metrics endpoint. Prometheus regularly fetches it. This is different from push-based systems like StatsD. Pull = simpler, more reliable. Target down? Prometheus knows immediately â€” scrape fails."

### ğŸ“š Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ: Prometheus Deep Dive (7-10 Ğ¼Ğ¸Ğ½)

**ĞœĞµÑ‚Ğ°Ñ„Ğ¾Ñ€Ğ°: Prometheus = Ğ’Ñ€Ğ°Ñ‡ Ñ Ğ¾Ğ±Ñ…Ğ¾Ğ´Ğ¾Ğ¼ Ğ¿Ğ°Ğ»Ğ°Ñ‚**

ĞŸÑ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒ Ğ±Ğ¾Ğ»ÑŒĞ½Ğ¸Ñ†Ñƒ:
- **ĞŸĞ°Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹** = Targets (Kubernetes pods, servers)
- **Ğ’Ñ€Ğ°Ñ‡** = Prometheus (Ğ´ĞµĞ»Ğ°ĞµÑ‚ Ğ¾Ğ±Ñ…Ğ¾Ğ´)
- **Ğ˜Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ** = Metrics (Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°, Ğ¿ÑƒĞ»ÑŒÑ, Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ)
- **ĞšĞ°Ñ€Ñ‚Ñ‹ Ğ¿Ğ°Ñ†Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²** = Time-series database
- **ĞœĞµĞ´ÑĞµÑÑ‚Ñ€Ğ°** = Alertmanager (Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²Ñ€Ğ°Ñ‡Ğ° ĞµÑĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°)

Ğ’Ñ€Ğ°Ñ‡ Ğ½Ğµ Ğ¶Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ĞºĞ° Ğ¿Ğ°Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ½ÑÑ‚. ĞĞ½ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ğ¾ Ğ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ğ°Ğ»Ğ°Ñ‚Ñ‹ Ğ¸ Ğ¸Ğ·Ğ¼ĞµÑ€ÑĞµÑ‚ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸. Ğ•ÑĞ»Ğ¸ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ½Ğµ Ñ‚Ğ°Ğº â€” ÑÑ€Ğ°Ğ·Ñƒ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ Ğ¸ Ñ€ĞµĞ°Ğ³Ğ¸Ñ€ÑƒĞµÑ‚.

---

### **Prometheus Components:**

#### 1. **Prometheus Server** (core):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PROMETHEUS SERVER                  â”‚
â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Retrieval â”‚â”€â”€â”€â”€â”€â†’â”‚ Time-series DB  â”‚  â”‚
â”‚  â”‚  (scraper) â”‚      â”‚   (TSDB)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â†“                      â†‘            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Service   â”‚      â”‚   HTTP Server   â”‚  â”‚
â”‚  â”‚ Discovery  â”‚      â”‚  (API + Web UI) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    Rules Engine (alerts)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Retrieval (scraper):**
- Pulls metrics from `/metrics` endpoints
- Default interval: 15s (configurable)
- Parallel scraping (hundreds of targets simultaneously)
- Timeout: 10s default

**Time-series DB (TSDB):**
- Compressed storage (1 byte per sample typical)
- Retention: 15 days default (configurable)
- Efficient Ğ´Ğ»Ñ millions of time-series
- Stored on disk (persistent volume needed)

**HTTP Server:**
- Web UI: http://prometheus:9090
- API: http://prometheus:9090/api/v1/query
- Query PromQL interactively

**Rules Engine:**
- Recording rules (pre-compute expensive queries)
- Alerting rules (detect problems, send to Alertmanager)

---

#### 2. **Targets** (what Prometheus monitors):

**Types:**
- **Kubernetes resources:** pods, nodes, services
- **Exporters:** node_exporter (system metrics), blackbox_exporter (endpoint probes)
- **Applications:** your app with `/metrics` endpoint

**Metrics endpoint format (Prometheus exposition format):**

```
# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="GET",status="200"} 1523
http_requests_total{method="GET",status="404"} 42
http_requests_total{method="POST",status="201"} 342

# HELP memory_usage_bytes Current memory usage
# TYPE memory_usage_bytes gauge
memory_usage_bytes 2147483648

# HELP http_request_duration_seconds HTTP request latency
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{le="0.1"} 500
http_request_duration_seconds_bucket{le="0.5"} 800
http_request_duration_seconds_bucket{le="1.0"} 950
http_request_duration_seconds_bucket{le="+Inf"} 1000
http_request_duration_seconds_sum 450.5
http_request_duration_seconds_count 1000
```

---

#### 3. **Service Discovery** (automatic target detection):

Ğ’Ğ¼ĞµÑÑ‚Ğ¾ hardcoded IP addresses:

```yaml
# âŒ BAD: manual targets
scrape_configs:
  - job_name: 'my-app'
    static_configs:
      - targets: ['10.0.1.5:8080', '10.0.1.6:8080']
```

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ service discovery:

```yaml
# âœ… GOOD: automatic discovery
scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
```

Prometheus Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ²ÑĞµ pods Ñ annotation `prometheus.io/scrape: "true"`.

**Supported service discovery:**
- Kubernetes (pods, services, nodes, endpoints)
- Consul, Eureka, Zookeeper
- AWS EC2, Azure, GCP
- File-based (JSON/YAML Ñ„Ğ°Ğ¹Ğ» Ñ targets)

---

#### 4. **Metric Types:**

**Counter** (only goes up):
```
http_requests_total 1000
# ...15 seconds later...
http_requests_total 1050  # +50 requests
```
Use cases: requests count, errors count, bytes sent

**Gauge** (can go up and down):
```
memory_usage_bytes 2147483648
# ...later...
memory_usage_bytes 2047483648  # decreased
```
Use cases: CPU %, memory usage, temperature, concurrent requests

**Histogram** (distribution of values):
```
http_request_duration_seconds_bucket{le="0.1"} 500   # 500 requests < 100ms
http_request_duration_seconds_bucket{le="0.5"} 800   # 800 requests < 500ms
http_request_duration_seconds_bucket{le="1.0"} 950   # 950 requests < 1s
```
Use cases: latency, request sizes

**Summary** (like histogram but client-side quantiles):
```
http_request_duration_seconds{quantile="0.5"} 0.15   # Median: 150ms
http_request_duration_seconds{quantile="0.95"} 0.45  # p95: 450ms
http_request_duration_seconds{quantile="0.99"} 0.80  # p99: 800ms
```
Use cases: latency percentiles

---

#### 5. **Labels** (dimensions Ğ´Ğ»Ñ filtering):

Metrics Ñ labels Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑÑ‚ slice and dice data:

```promql
# Total requests:
sum(http_requests_total)

# Requests Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ GET:
sum(http_requests_total{method="GET"})

# Requests GET + status 200:
sum(http_requests_total{method="GET",status="200"})

# Requests by method (Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°):
sum by (method) (http_requests_total)
```

**Best practices Ğ´Ğ»Ñ labels:**
- âœ… Low cardinality (method: GET/POST/PUT/DELETE â€” OK)
- âŒ High cardinality (user_id label â€” BAD! millions of users = millions of time-series)
- âœ… Filterable dimensions (status code, method, endpoint)
- âŒ Dynamic values (timestamps, UUIDs)

---

**Prometheus Configuration:**

`prometheus.yml` (main config file):

```yaml
global:
  scrape_interval: 15s       # How often to scrape targets
  evaluation_interval: 15s   # How often to evaluate rules
  scrape_timeout: 10s        # Scrape timeout

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

# Load alerting rules
rule_files:
  - "alerts.yml"

# Scrape configurations
scrape_configs:
  # Job 1: Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Job 2: Kubernetes nodes
  - job_name: 'kubernetes-nodes'
    kubernetes_sd_configs:
      - role: node
    relabel_configs:
      - source_labels: [__address__]
        regex: '(.*):10250'
        replacement: '${1}:9100'
        target_label: __address__

  # Job 3: Kubernetes pods (auto-discovery)
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
```

---

**GuÃ°rÃºn's wisdom:**
> "Prometheus is pull-based for reason. Push systems â€” targets must know where to send. Pull â€” Prometheus controls scraping. Target down? Prometheus sees immediately (scrape fails). Target up? Prometheus discovers automatically. Simple, reliable, scalable."

**LILITH:**
> "Prometheus architecture â€” ÑĞ»ĞµĞ³Ğ°Ğ½Ñ‚Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ‚Ğ°. Pull metrics, store time-series, query Ñ PromQL. ĞĞµ Ğ¿Ñ‹Ñ‚Ğ°ĞµÑ‚ÑÑ Ğ±Ñ‹Ñ‚ÑŒ Ğ²ÑĞµĞ¼ Ğ´Ğ»Ñ Ğ²ÑĞµÑ…. Metrics only. Logs â€” Loki. Traces â€” Jaeger. Focused tool does one thing well. Unix philosophy Ğ² Ğ¼Ğ¸Ñ€Ğµ monitoring."

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° (3-5 Ğ¼Ğ¸Ğ½)

**Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 2: Metric types**

Match metric type to use case:

1. HTTP requests count â†’ ?
2. Current memory usage â†’ ?
3. Request latency distribution â†’ ?
4. Current temperature â†’ ?
5. Bytes transferred total â†’ ?

<details>
<summary>ğŸ’¡ Ğ”ÑƒĞ¼Ğ°Ğ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹</summary>

**ĞÑ‚Ğ²ĞµÑ‚Ñ‹:**

1. **HTTP requests count** â†’ **Counter**
   - Only increases (never decreases)
   - Use `rate()` to get requests/sec

2. **Current memory usage** â†’ **Gauge**
   - Can go up and down
   - Use directly in queries

3. **Request latency distribution** â†’ **Histogram**
   - Need percentiles (p50, p95, p99)
   - Shows distribution across buckets

4. **Current temperature** â†’ **Gauge**
   - Can increase or decrease
   - Snapshot of current value

5. **Bytes transferred total** â†’ **Counter**
   - Only increases
   - Use `rate()` to get bytes/sec

**ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ Ğ¿Ğ°Ğ»ÑŒÑ†Ğ°:**
- Counting events â†’ Counter
- Measuring current value â†’ Gauge
- Measuring distribution â†’ Histogram/Summary

</details>

### ğŸ¤” Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ LILITH (1 Ğ¼Ğ¸Ğ½)

**LILITH:** "ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Prometheus Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ pull model (scraping), Ğ° Ğ½Ğµ push model (targets Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ metrics)?"

<details>
<summary>ğŸ’¡ Ğ”ÑƒĞ¼Ğ°Ğ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹</summary>

**ĞÑ‚Ğ²ĞµÑ‚Ñ‹ (3 Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹):**

**1. Failure detection:**
- **Pull:** Scrape fails â†’ Prometheus ÑÑ€Ğ°Ğ·Ñƒ Ğ·Ğ½Ğ°ĞµÑ‚ target down
- **Push:** Target down â†’ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ½ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ network issue Ğ¸Ğ»Ğ¸ target dead, Ğ½ĞµÑÑĞ½Ğ¾)

**2. Centralized control:**
- **Pull:** Prometheus ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ scraping (interval, timeout, targets)
- **Push:** Targets ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒÑÑ‚ (Ğ¼Ğ¾Ğ³ÑƒÑ‚ overwhelm collector, DDoS risk)

**3. Service discovery:**
- **Pull:** Prometheus Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ targets (Kubernetes service discovery)
- **Push:** Targets Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ·Ğ½Ğ°Ñ‚ÑŒ ĞºÑƒĞ´Ğ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ (configuration propagation problem)

**4. Debugging (bonus):**
- **Pull:** ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ curl target `/metrics` endpoint Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸
- **Push:** ĞÑƒĞ¶ĞµĞ½ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ Ğº target Ğ´Ğ»Ñ debugging

**ĞšĞ¾Ğ³Ğ´Ğ° push Ğ»ÑƒÑ‡ÑˆĞµ:**
- Short-lived jobs (batch jobs, serverless) â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Pushgateway
- Firewall Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ (target Ğ½Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ¸Ğ·Ğ²Ğ½Ğµ) â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ agent

**Ğ’Ñ‹Ğ²Ğ¾Ğ´:** Pull = default choice Ğ´Ğ»Ñ long-running services. Push = edge cases only.

</details>

---

## ğŸ”„ Ğ¦Ğ˜ĞšĞ› 3: PROMETHEUS INSTALLATION (15 Ğ¼Ğ¸Ğ½ÑƒÑ‚)

### ğŸ¬ Ğ¡ÑĞ¶ĞµÑ‚ (2 Ğ¼Ğ¸Ğ½)

**Ğ”ĞµĞ½ÑŒ 51, 11:30 â€” ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ**

**GuÃ°rÃºn:** "Theory enough. Time for practice. We deploy Prometheus on your Kubernetes cluster. I prepared manifests. But you apply them â€” learn by doing."

**ĞœĞ°ĞºÑ:** "Prometheus ĞºĞ°Ğº Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ pod Ğ² Kubernetes?"

**GuÃ°rÃºn:** "Yes. StatefulSet for Prometheus (needs persistent storage for TSDB). ConfigMap Ğ´Ğ»Ñ prometheus.yml. Service Ğ´Ğ»Ñ access. Standard Kubernetes patterns. Prometheus designed for containerized environments from start."

**GuÃ°rÃºn:** "After deployment â€” Prometheus automatically discovers your Kubernetes pods, nodes, services. No manual configuration. Magic of service discovery."

### ğŸ“š Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ: Prometheus Ğ½Ğ° Kubernetes (7-10 Ğ¼Ğ¸Ğ½)

**Deployment Options:**

#### Option 1: Prometheus Operator (recommended Ğ´Ğ»Ñ production)
- CRDs: ServiceMonitor, PodMonitor, PrometheusRule
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
- Ğ¡Ğ»Ğ¾Ğ¶Ğ½ĞµĞµ Ğ´Ğ»Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ°

#### Option 2: Helm Chart
- Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚
- Pre-configured Ğ´Ğ»Ñ Kubernetes
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ´Ğ»Ñ Episode 26

#### Option 3: Manual manifests (educational)
- ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ
- ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°

**ĞœÑ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Helm** (Ğ±Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ñ‚Ğ¾Ğ¹ Ğ¸ production-readiness).

### Prometheus Stack Components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PROMETHEUS STACK                     â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Prometheus  â”‚â—„â”€â”€â”€â”€â†’â”‚  Alertmanager  â”‚   â”‚
â”‚  â”‚   Server    â”‚      â”‚                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â†“                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Grafana   â”‚â—„â”€â”€â”€â”€â”€â”‚  Prometheus    â”‚   â”‚
â”‚  â”‚ Dashboards  â”‚      â”‚ (data source)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ node-       â”‚      â”‚  kube-state-   â”‚   â”‚
â”‚  â”‚ exporter    â”‚      â”‚  metrics       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Components:**

1. **Prometheus Server** â€” core (scraping, storage, queries)
2. **Alertmanager** â€” alert handling
3. **Grafana** â€” visualization
4. **node-exporter** â€” system metrics (CPU, Memory, Disk)
5. **kube-state-metrics** â€” Kubernetes state metrics (deployments, pods status)

### Installation Steps:

```bash
# 1. Add Helm repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# 2. Create namespace
kubectl create namespace monitoring

# 3. Install Prometheus stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --set prometheus.prometheusSpec.retention=15d \
  --set grafana.adminPassword=admin

# 4. Verify installation
kubectl get pods -n monitoring
```

**Installed resources:**

```
NAME                                                     READY   STATUS
prometheus-prometheus-kube-prometheus-prometheus-0       2/2     Running
prometheus-grafana-xxxxx                                 3/3     Running
prometheus-kube-state-metrics-xxxxx                      1/1     Running
prometheus-prometheus-node-exporter-xxxxx                1/1     Running
alertmanager-prometheus-kube-prometheus-alertmanager-0   2/2     Running
prometheus-kube-prometheus-operator-xxxxx                1/1     Running
```

**Access URLs:**

```bash
# Prometheus UI
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
# Open: http://localhost:9090

# Grafana UI
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# Open: http://localhost:3000
# Login: admin / admin

# Alertmanager UI
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-alertmanager 9093:9093
# Open: http://localhost:9093
```

**LILITH:**
> "Helm chart ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²ÑÑ‘ Ğ·Ğ° Ğ¾Ğ´Ğ½Ñƒ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ. Production-ready setup. ĞĞ¾ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ¹ Ñ‡Ñ‚Ğ¾ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸: Prometheus StatefulSet (persistent storage), ConfigMap (prometheus.yml), Service (exposure), ServiceAccount (RBAC permissions). Helm ÑƒĞ´Ğ¾Ğ±ĞµĞ½, Ğ½Ğ¾ Ğ½Ğµ magic. Ğ’ÑÑ‘ â€” Kubernetes resources."

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° (3-5 Ğ¼Ğ¸Ğ½)

**Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 3: Install Prometheus Stack**

```bash
# 1. Add Helm repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# 2. Create monitoring namespace
kubectl create namespace monitoring

# 3. Install stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --set prometheus.prometheusSpec.retention=15d \
  --set grafana.adminPassword=admin123

# 4. Wait for pods ready
kubectl wait --for=condition=Ready pods --all -n monitoring --timeout=300s

# 5. Port-forward Prometheus
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090 &

# 6. Port-forward Grafana
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80 &

# 7. Open browser
echo "Prometheus: http://localhost:9090"
echo "Grafana: http://localhost:3000 (admin/admin123)"
```

### ğŸ¤” Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ LILITH (1 Ğ¼Ğ¸Ğ½)

**LILITH:** "ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Prometheus Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ StatefulSet, Ğ° Ğ½Ğµ Deployment?"

<details>
<summary>ğŸ’¡ Ğ”ÑƒĞ¼Ğ°Ğ¹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹</summary>

**ĞÑ‚Ğ²ĞµÑ‚:** **Persistent storage + stable identity.**

**StatefulSet provides:**
1. **Persistent Volume** â€” TSDB data ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ restart
2. **Stable network identity** â€” prometheus-0 (Ğ½Ğµ random pod name)
3. **Ordered deployment** â€” guaranteed startup order
4. **Controlled updates** â€” rolling update Ñ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ĞµĞ¼

**ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ğ²Ğ°Ğ¶Ğ½Ğ¾:**
- Prometheus Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ time-series data Ğ½Ğ° Ğ´Ğ¸ÑĞºĞµ (retention 15 Ğ´Ğ½ĞµĞ¹)
- Pod restart â†’ data Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒÑÑ (PersistentVolume)
- Deployment Ğ±Ñ‹ ÑĞ¾Ğ·Ğ´Ğ°Ğ» Ğ½Ğ¾Ğ²Ñ‹Ğ¹ pod Ñ empty disk (data loss!)

**Kubernetes patterns:**
- **Stateless apps** (nginx, API) â†’ Deployment
- **Stateful apps** (databases, Prometheus) â†’ StatefulSet

</details>

---

## ğŸ”„ Ğ¦Ğ˜ĞšĞ› 4: PROMQL BASICS (12 Ğ¼Ğ¸Ğ½ÑƒÑ‚)

### ğŸ¬ Ğ¡ÑĞ¶ĞµÑ‚ (2 Ğ¼Ğ¸Ğ½)

**Ğ”ĞµĞ½ÑŒ 51, 13:00 â€” Prometheus UI**

**GuÃ°rÃºn:** "Prometheus installed. Now â€” query language. PromQL. Like SQL for metrics. You ask question â€” Prometheus answers with numbers."

*[GuÃ°rÃºn opens Prometheus UI: http://localhost:9090]*

**GuÃ°rÃºn:** "Simple query: `up`. Shows which targets are up (1) or down (0). Try it."

*[ĞœĞ°ĞºÑ Ğ²Ğ²Ğ¾Ğ´Ğ¸Ñ‚ query]*

**GuÃ°rÃºn:** "Good. Now complex query: `rate(http_requests_total[5m])`. Shows requests per second over last 5 minutes. PromQL powerful but not intuitive. I teach you patterns."

### ğŸ“š Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ: PromQL Query Language (6-8 Ğ¼Ğ¸Ğ½)

**PromQL = SQL Ğ´Ğ»Ñ time-series**

| SQL | PromQL |
|-----|--------|
| SELECT * FROM table | metric_name |
| WHERE status='200' | metric{status="200"} |
| COUNT(*) | sum(metric) |
| AVG(value) | avg(metric) |
| GROUP BY method | sum by (method) (metric) |

**Basic Queries:**

```promql
# 1. Instant vector (current value)
up  # Is target up? 1 = yes, 0 = no

# 2. Filter by labels
up{job="kubernetes-nodes"}  # Only nodes

# 3. Range vector (last 5 minutes)
http_requests_total[5m]  # All values from last 5m

# 4. Rate (per-second rate)
rate(http_requests_total[5m])  # Requests/sec

# 5. Sum aggregation
sum(rate(http_requests_total[5m]))  # Total req/sec

# 6. Group by label
sum by (method) (rate(http_requests_total[5m]))  # Per HTTP method
```

**Common Functions:**

```promql
# Rate (for counters)
rate(metric[5m])  # Per-second rate

# irate (instant rate, Ğ±Ğ¾Ğ»ĞµĞµ responsive)
irate(metric[5m])  # Instant rate

# Increase (total increase)
increase(metric[5m])  # Total count increase

# Avg/Min/Max
avg(metric)
min(metric)
max(metric)

# Aggregations
sum(metric)          # Total
avg(metric)          # Average
count(metric)        # Count of time-series
topk(5, metric)      # Top 5 values
bottomk(3, metric)   # Bottom 3 values
```

**Example Queries Ğ´Ğ»Ñ Kubernetes:**

```promql
# CPU usage per pod
sum by (pod) (rate(container_cpu_usage_seconds_total[5m]))

# Memory usage
container_memory_usage_bytes{namespace="shadow-ops"}

# Pod restarts
kube_pod_container_status_restarts_total

# HTTP request rate
rate(http_requests_total{status="200"}[5m])

# Error rate (%)
sum(rate(http_requests_total{status=~"5.."}[5m])) / 
sum(rate(http_requests_total[5m])) * 100
```

**LILITH:**
> "PromQL ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° ĞºĞ°Ğ¶ĞµÑ‚ÑÑ ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¼. rate([5m]), sum by (), {} vs []. ĞĞ¾ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¾ÑÑ‚Ğ°Ñ: metric â€” Ñ‡Ñ‚Ğ¾, {labels} â€” Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€, [time] â€” Ğ¾ĞºĞ½Ğ¾, function â€” Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ñ. Ğ—Ğ°Ğ¿Ğ¾Ğ¼Ğ½Ğ¸ patterns: rate Ğ´Ğ»Ñ counters, {} Ğ´Ğ»Ñ filter, by () Ğ´Ğ»Ñ group. ĞÑÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ â€” Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ°."

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° (3 Ğ¼Ğ¸Ğ½)

Open Prometheus UI (http://localhost:9090) and try:

```promql
# 1. Check targets status
up

# 2. CPU usage
rate(node_cpu_seconds_total[5m])

# 3. Memory usage
node_memory_MemAvailable_bytes

# 4. Kubernetes pods count
count(kube_pod_info)

# 5. Pod CPU by namespace
sum by (namespace) (rate(container_cpu_usage_seconds_total[5m]))
```

---

## ğŸ”„ Ğ¦Ğ˜ĞšĞ› 5: GRAFANA DASHBOARDS (12 Ğ¼Ğ¸Ğ½ÑƒÑ‚)

### ğŸ¬ Ğ¡ÑĞ¶ĞµÑ‚ (2 Ğ¼Ğ¸Ğ½)

**Ğ”ĞµĞ½ÑŒ 51, 14:00 â€” Grafana UI**

**GuÃ°rÃºn:** "Prometheus queries work. But staring at numbers â€” not comfortable. Grafana â€” visualization. Graphs, charts, alerts. Beautiful dashboards. I show you."

*[Opens Grafana: http://localhost:3000, login: admin/admin123]*

**GuÃ°rÃºn:** "Pre-installed dashboards from kube-prometheus-stack. Kubernetes cluster overview, node metrics, pod resources. Everything out of box. But you learn to create custom dashboard. This is real skill."

### ğŸ“š Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ: Grafana Dashboards (6-8 Ğ¼Ğ¸Ğ½)

**Dashboard Structure:**
```
Dashboard (collection of panels)
  â”œâ”€ Row 1: System Overview
  â”‚   â”œâ”€ Panel 1: CPU Usage (graph)
  â”‚   â””â”€ Panel 2: Memory Usage (graph)
  â”œâ”€ Row 2: Network
  â”‚   â”œâ”€ Panel 3: Network Traffic (graph)
  â”‚   â””â”€ Panel 4: Connections (stat)
  â””â”€ Row 3: Alerts
      â””â”€ Panel 5: Alert list
```

**Panel Types:**
- **Graph:** Time-series line chart
- **Stat:** Single number with trend
- **Gauge:** Progress bar/gauge
- **Table:** Data in table format
- **Heatmap:** Density visualization
- **Alert list:** Active alerts

**Creating Dashboard:**

1. Add data source (Prometheus already configured)
2. Create dashboard
3. Add panel
4. Write PromQL query
5. Configure visualization
6. Save dashboard

**Example Panel â€” CPU Usage:**

```
Query: rate(node_cpu_seconds_total{mode!="idle"}[5m]) * 100
Legend: {{instance}} - {{mode}}
Unit: percent (0-100)
Visualization: Time series
```

**Variables (templating):**

```
Variable: $namespace
Query: label_values(kube_pod_info, namespace)
Usage in query: container_memory_usage_bytes{namespace="$namespace"}
```

ĞŸĞ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°Ñ‚ÑŒÑÑ Ğ¼ĞµĞ¶Ğ´Ñƒ namespaces Ğ² dropdown.

**LILITH:**
> "Grafana â€” Photoshop Ğ´Ğ»Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº. PromQL Ğ´Ğ°Ñ‘Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Grafana Ğ´ĞµĞ»Ğ°ĞµÑ‚ Ğ¸Ñ… ĞºÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¼Ğ¸. Pre-built dashboards Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¸ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ€Ñ‚Ğ°. Custom dashboards â€” Ğ´Ğ»Ñ production. Ğ¤Ğ¾ĞºÑƒÑĞ¸Ñ€ÑƒĞ¹ Ğ½Ğ° actionable metrics: Ñ‡Ñ‚Ğ¾ broken? Ñ‡Ñ‚Ğ¾ bottleneck? Ğ½Ğµ vanity metrics."

### ğŸ’» ĞŸÑ€Ğ°ĞºÑ‚Ğ¸ĞºĞ° (3 Ğ¼Ğ¸Ğ½)

**Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ: Create simple dashboard**

1. Open Grafana â†’ Dashboards â†’ New Dashboard
2. Add panel â†’ Prometheus query:
   ```promql
   sum(rate(container_cpu_usage_seconds_total{namespace="shadow-ops"}[5m])) by (pod)
   ```
3. Panel title: "CPU Usage by Pod"
4. Visualization: Time series
5. Legend: {{pod}}
6. Save dashboard: "Shadow Ops Monitoring"

---

## ğŸ”„ Ğ¦Ğ˜ĞšĞ› 6: ALERTMANAGER & ALERTING RULES (15 Ğ¼Ğ¸Ğ½ÑƒÑ‚)

### ğŸ¬ Ğ¡ÑĞ¶ĞµÑ‚ (2 Ğ¼Ğ¸Ğ½)

**Ğ”ĞµĞ½ÑŒ 51, 15:30 â€” Alert testing**

**GuÃ°rÃºn:** "Dashboards pretty. But you Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ watch screens 24/7. Alerts â€” automatic notifications. Prometheus detects problem, Alertmanager sends alert. Email, Slack, PagerDuty. Whatever you need."

*[GuÃ°rÃºn Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ alert firing]*

**GuÃ°rÃºn:** "This alert: 'Pod Ğ½Ğµ Ready more than 5 minutes'. Fires when problem. Resolves when fixed. Self-healing notifications. Production requires this."

### ğŸ“š Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ: Alerting (7-10 Ğ¼Ğ¸Ğ½)

**Alerting Rule Example:**

```yaml
# prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: shadow-ops-alerts
  namespace: monitoring
spec:
  groups:
  - name: shadow-ops
    interval: 30s
    rules:
    # Alert 1: High CPU
    - alert: HighCPU
      expr: sum by (pod) (rate(container_cpu_usage_seconds_total{namespace="shadow-ops"}[5m])) > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High CPU usage on pod {{ $labels.pod }}"
        description: "CPU usage > 90% for 5 minutes"
    
    # Alert 2: Pod not Ready
    - alert: PodNotReady
      expr: kube_pod_status_phase{namespace="shadow-ops",phase!="Running"} == 1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Pod {{ $labels.pod }} not Ready"
        description: "Pod in {{ $labels.phase }} phase for 5 minutes"
```

**Alert States:**
- **Inactive:** Condition false (no problem)
- **Pending:** Condition true, waiting `for` duration
- **Firing:** Condition true for `for` duration â†’ alert sent

**Alertmanager Config:**

```yaml
# alertmanager-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-prometheus-kube-prometheus-alertmanager
  namespace: monitoring
stringData:
  alertmanager.yaml: |
    global:
      slack_api_url: 'https://hooks.slack.com/services/xxx'
    
    route:
      receiver: 'slack-notifications'
      group_by: ['alertname', 'cluster']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h
    
    receivers:
    - name: 'slack-notifications'
      slack_configs:
      - channel: '#alerts'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
```

**Best Practices:**
- âœ… Alert Ğ½Ğ° symptoms (high latency) Ğ½Ğµ causes (high CPU)
- âœ… Include runbooks Ğ² annotations
- âœ… Use severity levels (critical, warning, info)
- âœ… Group related alerts (Ğ½Ğµ spam 100 alerts)
- âŒ Don't alert Ğ½Ğ° everything (alert fatigue)

---

## ğŸ”„ Ğ¦Ğ˜ĞšĞ› 7: KUBERNETES MONITORING (12 Ğ¼Ğ¸Ğ½ÑƒÑ‚)

### ğŸ“š Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ: Monitoring K8s (ÑĞ¾ĞºÑ€Ğ°Ñ‰Ñ‘Ğ½Ğ½Ğ¾)

**Key Metrics:**

```promql
# Cluster health
up{job="kubernetes-nodes"}

# Pod status
kube_pod_status_phase

# Resource usage
container_cpu_usage_seconds_total
container_memory_usage_bytes

# Deployment status
kube_deployment_status_replicas_available
```

**ServiceMonitor CRD** (auto-discovery):

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: shadow-web-monitor
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: shadow-web
  endpoints:
  - port: metrics
    interval: 30s
```

---

## ğŸ”„ Ğ¦Ğ˜ĞšĞ› 8: TROUBLESHOOTING & BEST PRACTICES (12 Ğ¼Ğ¸Ğ½ÑƒÑ‚)

### ğŸ“š Ğ¢ĞµĞ¾Ñ€Ğ¸Ñ: Common Issues (ÑĞ¾ĞºÑ€Ğ°Ñ‰Ñ‘Ğ½Ğ½Ğ¾)

**Issue 1: No Data in Grafana**
- Check: Prometheus targets (Status â†’ Targets)
- Check: Prometheus data source Ğ² Grafana
- Check: PromQL query syntax

**Issue 2: Alert Ğ½Ğµ fires**
- Check: Alerting rules loaded (Status â†’ Rules)
- Check: Alert condition true (Graph â†’ Expression)
- Check: `for` duration (pending â†’ firing time)

**Issue 3: High Cardinality**
- Problem: Too many unique label combinations
- Symptom: Prometheus OOMKilled, slow queries
- Solution: Reduce labels (remove user_id, request_id)

**Best Practices:**
- âœ… Monitor SLIs (Service Level Indicators): latency, availability, error rate
- âœ… Define SLOs (Service Level Objectives): 99.9% uptime, p95 < 500ms
- âœ… Alert Ğ½Ğ° SLO violations
- âœ… Use dashboards Ğ´Ğ»Ñ exploration, alerts Ğ´Ğ»Ñ action
- âœ… Retention: 15-30 days (longer = more storage)

---

## ğŸ“‹ ĞŸĞ ĞĞšĞ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ—ĞĞ”ĞĞĞ˜Ğ¯

### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 1: Install Prometheus Stack âœ… (Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¾ Ğ² Ğ¦Ğ¸ĞºĞ»Ğµ 3)

### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 2: Create Custom Dashboard

1. Login to Grafana
2. Create new dashboard
3. Add panels:
   - CPU usage by pod
   - Memory usage by pod
   - Network traffic
   - Pod status
4. Add variables: $namespace
5. Save dashboard

### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 3: Configure Alert Rule

Create `custom-alerts.yaml`:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: custom-alerts
  namespace: monitoring
spec:
  groups:
  - name: custom
    rules:
    - alert: HighMemory
      expr: container_memory_usage_bytes{namespace="shadow-ops"} / container_spec_memory_limit_bytes > 0.9
      for: 5m
      annotations:
        summary: "High memory usage"
```

Apply: `kubectl apply -f custom-alerts.yaml`

### Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ 4: Test Alert

1. Generate high CPU: `kubectl run stress --image=polinux/stress -- stress --cpu 4`
2. Wait 5 minutes
3. Check Alertmanager: http://localhost:9093
4. Verify alert fires
5. Delete stress pod: `kubectl delete pod stress`
6. Verify alert resolves

---

## ğŸ¬ EPILOGUE: Ğ“Ğ›ĞĞ—Ğ ĞĞ¢ĞšĞ Ğ«Ğ¢Ğ«

### Ğ”ĞµĞ½ÑŒ 52, 17:00 â€” Monitoring Dashboard

**GuÃ°rÃºn:** "Good work. Prometheus collects. Grafana visualizes. Alertmanager notifies. You have eyes now. Production infrastructure visible."

*[ĞĞ° Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğµ: 10+ dashboards, all green, metrics flowing]*

**GuÃ°rÃºn:** "Before â€” kubectl get pods. Now â€” real-time visibility. CPU, memory, disk, network, HTTP requests, errors, latency. Everything. And when problem â€” alert fires before users notice."

**ĞœĞ°ĞºÑ:** "ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 'Ñ‡Ñ‚Ğ¾ ÑĞ»Ğ¾Ğ¼Ğ°Ğ»Ğ¾ÑÑŒ', Ğ½Ğ¾ Ğ¸ 'Ñ‡Ñ‚Ğ¾ ÑĞºĞ¾Ñ€Ğ¾ ÑĞ»Ğ¾Ğ¼Ğ°ĞµÑ‚ÑÑ'. Ğ¢Ñ€ĞµĞ½Ğ´Ñ‹."

**GuÃ°rÃºn:** "Exactly. This is observability. Not just 'is it up?' but 'how is it performing?'. Production requires this. Without monitoring â€” you are blind. With monitoring â€” you see everything."

**Viktor** (Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ²Ğ¾Ğ½Ğ¾Ğº): "ĞœĞ°ĞºÑ, Episode 26 complete. Monitoring Ğ°ĞºÑ‚Ğ¸Ğ²ĞµĞ½. Prometheus scraping, Grafana dashboards, Alertmanager configured. Real-time visibility. Tomorrow â€” Episode 27. Ã“lafur teaches performance tuning. Monitoring shows problems. Performance tuning fixes them."

**LILITH:** "ĞÑ‚ ÑĞ»ĞµĞ¿Ğ¾Ğ³Ğ¾ kubectl Ğº Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ observability. Prometheus Ğ²Ğ¸Ğ´Ğ¸Ñ‚ ĞºĞ°Ğ¶Ğ´ÑƒÑ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ. Grafana Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ñ€ĞµĞ½Ğ´Ñ‹. Alertmanager Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´Ğ°ĞµÑ‚ Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ñ…. Production infrastructure Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ğº Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ñƒ. Episode 27 â€” Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¾Ğ³Ğ¾ Ñ‡Ñ‚Ğ¾ Ğ²Ğ¸Ğ´Ğ¸ÑˆÑŒ."

---

## ğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ Ğ­ĞŸĞ˜Ğ—ĞĞ”Ğ

**Ğ§Ñ‚Ğ¾ Ğ²Ñ‹ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ğ»Ğ¸:**
- âœ… Observability principles (metrics, logs, traces)
- âœ… Prometheus architecture (scraping, TSDB, PromQL)
- âœ… Prometheus installation (Helm chart, Kubernetes deployment)
- âœ… PromQL queries (rate, sum, aggregations)
- âœ… Grafana dashboards (panels, variables, visualization)
- âœ… Alertmanager (alerting rules, notifications)
- âœ… Kubernetes monitoring (ServiceMonitor, kube-state-metrics)
- âœ… Troubleshooting (no data, alert issues, high cardinality)

**Monitoring stack deployed:**
- 1 Prometheus Server (StatefulSet)
- 1 Grafana instance
- 1 Alertmanager
- N node-exporters (per node)
- 1 kube-state-metrics
- Custom dashboards + alert rules

**Time spent:** 5-6 hours  
**Complexity:** â­â­â­â­â˜†  
**Production readiness:** 70% (monitoring active, needs alert tuning)

---

## ğŸ”— Ğ¡Ğ›Ğ•Ğ”Ğ£Ğ®Ğ©Ğ˜Ğ™ Ğ­ĞŸĞ˜Ğ—ĞĞ”

**Episode 27: Performance Tuning**
- Performance profiling (perf, top, iostat)
- Kernel tuning (sysctl optimization)
- Database optimization (SQL queries, indexes)
- Caching strategies (Redis)
- **ĞŸĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶:** Ã“lafur ÃÃ³rsson (performance engineer)

**Ğ”ĞµĞ½ÑŒ 53 Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸** â€” 7 Ğ´Ğ½ĞµĞ¹ Ğ´Ğ¾ Ñ„Ğ¸Ğ½Ğ°Ğ»Ğ°

---

<div align="center">

**"Without monitoring â€” you are blind. With monitoring â€” you have eyes."** â€” GuÃ°rÃºn Ãsta

**EPISODE 26 COMPLETE** âœ…

*Ğ”ĞµĞ½ÑŒ 52 Ğ¸Ğ· 60 | Ğ ĞµĞ¹ĞºÑŒÑĞ²Ğ¸Ğº, Ğ˜ÑĞ»Ğ°Ğ½Ğ´Ğ¸Ñ ğŸ‡®ğŸ‡¸ | Monitoring infrastructure active*

**Next:** Episode 27 â€” Performance Tuning âš¡

</div>